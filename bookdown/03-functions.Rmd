```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=12, fig.height=8,fig.align = "center",
                      out.width = "100%")
library(DBI)
library(dplyr)
## library(cmap4r)
```
# Functions

## Getting started

Data in the CMAP database exists in tables, and can be accessed by specific
table names, and variable names therein. For instance, sea surface temperature
is from the table `"tblSST_AVHRR_OI_NRT"`, and the variable name is `"sst"`. The
full set of table names and variable names can be found here:

https://cmap.readthedocs.io/en/latest/catalog/catalog.html

Each table contains many data "rows", which are indexed by "keys" of the four
values:

**(Time, Latitude, Longitude, Depth)**

Most functions in this package will involve using these data key values, or
user-specified ranges of these keys, for certain operations. The most basic
operation, explained next, is to download a dataset from a time and space range
of interest.

## Download data

When retrieving the data from **CMAP**, the user specifies the following:

+ Name of table (`table.name`)
+ Names of variables in that table (`sel_var`)
+ "Range" variable (list containing ranges of `latitude`, `longitude`, `depth`,
  and `time`)

These are used in the `get_table()` function, which downloads the data as a
data frame.

```{r message=FALSE, warning=FALSE, echo=TRUE, eval=FALSE}
con <- dbConnect(odbc::odbc(), DSN="CMAP-MSSQL",UID="ArmLab",PWD="ArmLab2018")

## Input: Table name; variable name, space time range information
table_name = 'tblsst_AVHRR_OI_NRT'     
sel_var = 'sst'                         
range_var <- list(lat = c(10,70),
                  lon = c(-180, -80),
                  time <- c('2016-04-30', '2016-04-30'))

## Subset selection:
tbl_subset <- get_table(con, table_name, sel_var, range_var)
head(tbl_subset)

dbDisconnect(con)
```

## Summarize data

A typical table's "attributes" include:

+ Name of variables,
+ Type of variables, i.e., quantitative, qualitative, time, 
+ Size of the table,
+ Space-time range information,
+ Numerical variable range summary.

These are used in the various following functions, which are designed to
summarize data tables by extracting these table attributes. This is useful for
learning about the tables without downloading them prior to analysis. Here are
some key examples:

```{r  message=FALSE, warning=FALSE, echo=TRUE, eval=FALSE}
con <- dbConnect(odbc::odbc(), DSN="CMAP-MSSQL",UID="ArmLab",PWD="ArmLab2018")
DBI::dbExecute(con, "SET QUOTED_IDENTIFIER ON")

## Choose a table:
table_name <-  "tblsst_AVHRR_OI_NRT"

# Variable name in the table
tbl_fields <- dbListFields(con, table_name)
print(tbl_fields)

## Obtain a sample of the data 
tbl_fields <- tbl_sample(con, table_name, n=5)
print(tbl_fields)

# See the data type of each column in the table
tbl_colClass = tbl_vartype(con, table_name)
print(tbl_colClass)

# Number of observations
nObs = tbl_nobs(con, table_name)
print(nObs)

# Space/time range of the table (slow if table is big)
tbl_spacetime = tbl_spacetime_range(con, table_name)
print(tbl_spacetime)

# Range of only the numeric variables:
tbl_range <- tbl_numvar_range(con,table_name)
print(tbl_range)

dbDisconnect(con)
```


## Visualization

There are two built-in options for making plots -- scatter plots to compare two
variable of interest, or histograms of individual variables.

### Scatterplot of two variables

The `plot_xy()` function makes a scatterplot of two variables (from two tables),
aggregated across a variable called `agg_var`. Why aggregate though? The two
variables from the two tables might exist at different time/space
resolutions. Because of this potential discrepancy in data resolution, averaging
the two datasets at some resolution according to, say, `agg_var="time"`, by day,
is a useful step before plotting a relationship between the two.

There are currently two methods for plotting -- one using the `ggplot2` R
package, and another using `plotly`.

<!-- **plot_xy** function download the data, and output a list which contain a) plot -->
<!-- object: **plot_ly/ggplot**; b) corresponding data tables. -->

```{r message=FALSE, warning=FALSE, echo=TRUE, eval=FALSE}
con <- dbConnect(odbc::odbc(), DSN="CMAP-MSSQL",UID="ArmLab",PWD="ArmLab2018")

## Define variables
table_list <- c('tblSST_AVHRR_OI_NRT', 'tblAltimetry_REP') 
var_list <-  c('sst', 'sla')  
range_var <- list()
range_var$lat <- c(25,30)
range_var$lon <- c(-160, -155)
range_var$time <- c('2016-03-29', '2016-05-29')
agg_var <- 'time' ## agg_var <- 'lat'

## -----------------------------------
## Dataset from table I
selIndex <- 1
table_name <- table_list[selIndex]                       # Specify table name I
sel_var <- var_list[selIndex]                            # Variable from table name I  
tbl_subset_x <- get_aggtable(con, table_name, sel_var, range_var, agg_var)
head(tbl_subset_x)

## Dataset from table II
selIndex <- 2
table_name <- table_list[selIndex]                       # Specify table name II
sel_var <- var_list[selIndex]                            # Variable from table name II
tbl_subset_y <- get_aggtable(con, table_name, sel_var, range_var, agg_var)
head(tbl_subset_y)

## Plot
out <- plot_xy(con, table_list, var_list, range_var, agg_var, type = 'plotly')
out$plot
dbDisconnect(con)
```

### Histograms 

To generate a histogram plot of a single variable of interest, simply specify which variable and which time/lat/lon/depth range, and use the function `plot_hist()` as follows:

```{r message=FALSE, warning=FALSE, echo=TRUE, eval=FALSE}
con <- dbConnect(odbc::odbc(), DSN="CMAP-MSSQL",UID="ArmLab",PWD="ArmLab2018")

## Specify what to query
table_name <- c('tblSST_AVHRR_OI_NRT')
sel_name <-  c('sst')
range_var <- list()
range_var$lat <- c(20, 24)
range_var$lon <- c(-170, 150)
range_var$time <- c('2016-04-30', '2016-04-30')

## Obtain a data table:
tbl_subset <- get_table(con, table_name, sel_var, range_var)
head(tbl_subset)

## Make plot
p <- plot_hist(tbl_subset, 'plotly', sel_var)
p

dbDisconnect(con)
```

## Colocalize data

First of all, what does it mean to *colocalize*? Imagine a ship moving along a
trajectory, whose location in space and time is recorded in
latitude/longitude/time. Then, we'd like to obtain data like sea surface
temperature or salinity, *as if we were recording it along the ship's
trajectory*. Colocalization simply means retrieving such data manually from the
database, by querying from the *vicinity* of each lat/lon/time triplet and
summarizing it (e.g. taking the average).

The size of the vicinity is define by the user-specified slack in longitude,
latitude and time. For instance, one could ask for 1 degrees of slack in
longitude and latitude, and 6 hours of slack in time.

Long story short, the basic idea is: query "rectangle" region's subtable from
the databse for every lat/lon/time triplet of interest, for each variable.

The main function to do this is `matchSource_onetable`, which colocalizes data
for one table at a time (the `table_name` variable from the catalog), and one or
more variables in that table (the `sel_var` variable, again from the
catalog). The latitude/longitude/time triplets are to be in a CSV file whose
path you'll supply in the variable `source`. Here is a short example:

```{r, echo=TRUE, eval=FALSE}
## Setup 
con = DBI::dbConnect(odbc::odbc(), DSN="CMAP-MSSQL",UID="ArmLab",PWD="ArmLab2018")
latMargin = 0_3
lonMargin = 0_3
timeMargin = 1
source = '~/Desktop/MGL1704-veryshort.csv'
table.name = "tblSST_AVHRR_OI_NRT"
sel_var = "sst"
res = matchSource_onetable(con, source, table_name, sel_var, latMargin, lonMargin, timeMargin)
print(head(res))
```


## Other useful functions

Suggest some!
